{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eaee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['STPSF_PATH'] = '/blue/adamginsburg/t.yoo/from_red/stpsf-data'\n",
    "import stpsf as webbpsf\n",
    "\n",
    "webbpsf.conf.STPSF_PATH = '/blue/adamginsburg/t.yoo/from_red/stpsf-data'\n",
    "\n",
    "# Continue with other imports\n",
    "from webbpsf.utils import to_griddedpsfmodel\n",
    "from jwst.datamodels import dqflags\n",
    "\n",
    "\n",
    "from stpsf.psf_model import WrappedPSFModel\n",
    "from stpsf.psf_grid import PSFGrid\n",
    "from stpsf.psf_utils import get_psf_grid_from_file\n",
    "from stpsf.psf_utils import get_psf_grid_from_webbpsf\n",
    "from stpsf.psf_utils import get_stampsz_from_psfgrid\n",
    "import numpy as np\n",
    "\n",
    "from photutils.detection import DAOStarFinder\n",
    "class WrappedPSFModel(crowdsource.psf.SimplePSF):\n",
    "    \"\"\"\n",
    "    wrapper for photutils GriddedPSFModel\n",
    "    \"\"\"\n",
    "    def __init__(self, psfgridmodel, stampsz=19):\n",
    "        self.psfgridmodel = psfgridmodel\n",
    "        self.default_stampsz = stampsz\n",
    "\n",
    "    def __call__(self, col, row, stampsz=None, deriv=False):\n",
    "\n",
    "        if stampsz is None:\n",
    "            stampsz = self.default_stampsz\n",
    "\n",
    "        parshape = numpy.broadcast(col, row).shape\n",
    "        tparshape = parshape if len(parshape) > 0 else (1,)\n",
    "\n",
    "        # numpy uses row, column notation\n",
    "        rows, cols = np.indices((stampsz, stampsz)) - (np.array([stampsz, stampsz])-1)[:, None, None] / 2.\n",
    "\n",
    "        # explicitly broadcast\n",
    "        col = np.atleast_1d(col)\n",
    "        row = np.atleast_1d(row)\n",
    "        #rows = rows[:, :, None] + row[None, None, :]\n",
    "        #cols = cols[:, :, None] + col[None, None, :]\n",
    "\n",
    "        # photutils seems to use column, row notation\n",
    "        # only works with photutils <= 1.6.0 - but is wrong there\n",
    "        #stamps = self.psfgridmodel.evaluate(cols, rows, 1, col, row)\n",
    "        # it returns something in (nstamps, row, col) shape\n",
    "        # pretty sure that ought to be (col, row, nstamps) for crowdsource\n",
    "\n",
    "        # andrew saydjari's version here:\n",
    "        # it returns something in (nstamps, row, col) shape\n",
    "        stamps = []\n",
    "        for i in range(len(col)):\n",
    "            # the +0.5 is required to actually center the PSF (empirically)\n",
    "            #stamps.append(self.psfgridmodel.evaluate(cols+col[i]+0.5, rows+row[i]+0.5, 1, col[i], row[i]))\n",
    "            # the above may have been true when we were using (incorrectly) offset PSFs\n",
    "            stamps.append(self.psfgridmodel.evaluate(cols+col[i], rows+row[i], 1, col[i], row[i]))\n",
    "\n",
    "        stamps = np.array(stamps)\n",
    "\n",
    "        # for oversampled stamps, they may not be normalized\n",
    "        stamps /= stamps.sum(axis=(1,2))[:,None,None]\n",
    "        # this is evidently an incorrect transpose\n",
    "        #stamps = np.transpose(stamps, axes=(0,2,1))\n",
    "\n",
    "        if deriv:\n",
    "            dpsfdrow, dpsfdcol = np.gradient(stamps, axis=(1, 2))\n",
    "\n",
    "        ret = stamps\n",
    "        if parshape != tparshape:\n",
    "            ret = ret.reshape(stampsz, stampsz)\n",
    "            if deriv:\n",
    "                dpsfdrow = dpsfdrow.reshape(stampsz, stampsz)\n",
    "                dpsfdcol = dpsfdcol.reshape(stampsz, stampsz)\n",
    "        if deriv:\n",
    "            ret = (ret, dpsfdcol, dpsfdrow)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def render_model(self, col, row, stampsz=None):\n",
    "        \"\"\"\n",
    "        this function likely does nothing?\n",
    "        \"\"\"\n",
    "        if stampsz is not None:\n",
    "            self.stampsz = stampsz\n",
    "\n",
    "        rows, cols = np.indices(self.stampsz, dtype=float) - (np.array(self.stampsz)-1)[:, None, None] / 2.\n",
    "\n",
    "        return self.psfgridmodel.evaluate(cols, rows, 1, col, row).T.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inject_synthetic_stars(img):\n",
    "    # use psf_grid in stpsf package to inject synthetic stars\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_psf_model(filtername, proposal_id, field,\n",
    "                  module,\n",
    "                  obsdate=None,\n",
    "                  target='w51',\n",
    "                  stampsz=19,\n",
    "                  oversample=1,\n",
    "                  basepath='/orange/adamginsburg/jwst/'):\n",
    "    \"\"\"\n",
    "    Return two types of PSF model, the first for DAOPhot and the second for Crowdsource\n",
    "    \"\"\"\n",
    "\n",
    "    basepath = f'{basepath}/{target}'\n",
    "\n",
    "\n",
    "    \n",
    "    if True:\n",
    "        \n",
    "        has_downloaded = False\n",
    "        ntries = 0\n",
    "        while not has_downloaded:\n",
    "            ntries += 1\n",
    "            try:\n",
    "                print(\"Attempting to download WebbPSF data\", flush=True)\n",
    "                if filtername.upper() in ['F140M', 'F150W', 'F162M', 'F164N', 'F182M', 'F187N',\n",
    "                                  'F200W', 'F210M', 'F212N', 'F250M', 'F300M', 'F322W2',\n",
    "                                  'F335M', 'F356W', 'F360M', 'F410M', 'F430M', 'F444W',\n",
    "                                  'F460M', 'F466N', 'F480M']:\n",
    "                    nrc = webbpsf.NIRCam()\n",
    "                else:\n",
    "                    nrc = webbpsf.MIRI()\n",
    "                nrc.load_wss_opd_by_date(f'{obsdate}T00:00:00')\n",
    "                nrc.filter = filtername\n",
    "                if module in ('nrca', 'nrcb'):\n",
    "                    if 'F4' in filtername.upper() or 'F3' in filtername.upper():\n",
    "                        nrc.detector = f'{module.upper()}5' # I think NRCA5 must be the \"long\" detector?\n",
    "                    else:\n",
    "                        nrc.detector = f'{module.upper()}1' #TODO: figure out a way to use all 4?\n",
    "                    # default oversampling is 4\n",
    "                    grid = nrc.psf_grid(num_psfs=16, all_detectors=False, verbose=True, save=True)\n",
    "                elif 'mirimage' in module:\n",
    "                    print('module', module, flush=True)\n",
    "                    print(nrc.detector)\n",
    "                    nrc.detector = 'MIRIM'\n",
    "                    grid = nrc.psf_grid(num_psfs=16, all_detectors=False, verbose=True, save=True)\n",
    "                else:\n",
    "                    grid = nrc.psf_grid(num_psfs=16, all_detectors=True, verbose=True, save=True)\n",
    "                has_downloaded = True\n",
    "            except (urllib3.exceptions.ReadTimeoutError, requests.exceptions.ReadTimeout, requests.HTTPError) as ex:\n",
    "                print(f\"Failed to build PSF: {ex}\", flush=True)\n",
    "            except Exception as ex:\n",
    "                print(ex, flush=True)\n",
    "                if ntries > 10:\n",
    "                    # avoid infinite loops\n",
    "                    raise ValueError(\"Failed to download PSF, probably because of an error listed above\")\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if True:\n",
    "            if isinstance(grid, list):\n",
    "                grid = grid[0]\n",
    "            return grid, WrappedPSFModel(grid, stampsz=stampsz)\n",
    "        \n",
    "def load_data(filename):\n",
    "    fh = fits.open(filename)\n",
    "    im1 = fh\n",
    "    data = im1['SCI'].data\n",
    "    try:\n",
    "        wht = im1['WHT'].data\n",
    "    except KeyError:\n",
    "        wht = None\n",
    "    err = im1['ERR'].data\n",
    "    instrument = im1[0].header['INSTRUME']\n",
    "    telescope = im1[0].header['TELESCOP']\n",
    "    obsdate = im1[0].header['DATE-OBS']\n",
    "    return fh, im1, data, wht, err, instrument, telescope, obsdate    \n",
    "\n",
    "def get_filenames(basepath, filtername, proposal_id, field, each_suffix, module, pupil='clear', visitid='001'):\n",
    "\n",
    "    # jw01182004002_02101_00012_nrcalong_destreak_o004_crf.fits\n",
    "    # jw02221001001_07101_00012_nrcalong_destreak_o001_crf.fits\n",
    "    # jw02221001001_05101_00022_nrcb3_destreak_o001_crf.fits\n",
    "        #jw06151002001_02101_00001_mirimage_i2d.fits\n",
    "\n",
    "    glstr = f'{basepath}/{filtername}/pipeline/jw0{proposal_id}{field}*{module}*_{each_suffix}.fits'\n",
    "    \n",
    "  \n",
    "    fglob = glob.glob(glstr)\n",
    "    for st in fglob:\n",
    "        print(st)\n",
    "        if 'align' in st or 'uncal' in st:\n",
    "            print(f\"Removing {st} from glob string because it is an alignment file\")\n",
    "            fglob.remove(st)\n",
    "    if len(fglob) == 0:\n",
    "        raise ValueError(f\"No matches found to {glstr}\")\n",
    "    else:\n",
    "        return fglob\n",
    "\n",
    "def main(basepath='/orange/adamginsburg/jwst/w51/',\n",
    "        proposal_id='6151',\n",
    "         field='02001',\n",
    "         filtername='F140M',\n",
    "         module='nrca1',\n",
    "         visitid='001',\n",
    "         target='w51'):\n",
    "\n",
    "    filenames = get_filenames(basepath, filtername, proposal_id,\n",
    "                                              field, visitid=visitid,\n",
    "                                              each_suffix=options.each_suffix,\n",
    "                                              module=module, pupil='clear')\n",
    "    fh, im1, data, wht, err, instrument, telescope, obsdate = load_data(filename)\n",
    "\n",
    "    # set up coordinate system\n",
    "    ww = wcs.WCS(im1[1].header)\n",
    "    pixscale = ww.proj_plane_pixel_area()**0.5\n",
    "    cen = ww.pixel_to_world(im1[1].shape[1]/2, im1[1].shape[0]/2)\n",
    "    grid, psf_model = get_psf_model(filtername, proposal_id, field,\n",
    "                                    module=module,\n",
    "                                    # if we're doing each exposure, we want the full grid\n",
    "                                    target=target,\n",
    "                                    obsdate=obsdate,\n",
    "                                    basepath='/orange/adamginsburg/jwst/')\n",
    "\n",
    "    filtered_errest = np.nanmedian(err)\n",
    "    nsigma = 5\n",
    "    daofind_tuned = DAOStarFinder(threshold=nsigma * filtered_errest,\n",
    "                                  fwhm=fwhm_pix, roundhi=1.0, roundlo=-1.0,\n",
    "                                  sharplo=0.30, sharphi=1.40)\n",
    "\n",
    "    kernel = Gaussian2DKernel(x_stddev=fwhm_pix/2.355)\n",
    "    mask = np.isnan(data)\n",
    "    if 'DQ' in im1:\n",
    "        dqarr = im1['DQ'].data\n",
    "        is_saturated = (dqarr & dqflags.pixel['SATURATED']) != 0\n",
    "        # we want original data_ to be untouched for imshowing diagnostics etc.\n",
    "        data_ = data.copy()\n",
    "        data_[is_saturated] = np.nan\n",
    "        mask |= is_saturated\n",
    "    else:\n",
    "        data_ = data\n",
    "\n",
    "    nan_replaced_data = interpolate_replace_nans(data_, kernel, convolve=convolve_fft)\n",
    "\n",
    "    finstars = daofind_tuned(nan_replaced_data,\n",
    "                             mask=mask)\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
